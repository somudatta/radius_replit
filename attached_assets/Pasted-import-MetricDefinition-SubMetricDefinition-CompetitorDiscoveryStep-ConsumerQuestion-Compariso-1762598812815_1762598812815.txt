import { MetricDefinition, SubMetricDefinition, CompetitorDiscoveryStep, ConsumerQuestion, ComparisonDimension } from './types';

// ============================================
// MAIN METRICS DEFINITIONS (AIC, CES, MTS)
// ============================================

export const METRIC_DEFINITIONS: Record<string, MetricDefinition> = {
  AIC: {
    code: 'AIC',
    title: 'Answerability & Intent Coverage',
    description: 'Measures how well your content answers user queries and covers their intent in generative AI responses.',
    weight: 0.40,
    calculation_method: 'Average of 5 sub-scores (s1-s5), each rated 0-10. Final AIC score = (s1 + s2 + s3 + s4 + s5) / 5',
    scoring_anchors: [
      { range: '0-2', label: 'Critical', description: 'Missing core information, unable to answer basic queries' },
      { range: '2-4', label: 'Weak', description: 'Partial coverage with significant gaps' },
      { range: '4-6', label: 'Adequate', description: 'Covers basics but lacks depth' },
      { range: '6-8', label: 'Strong', description: 'Comprehensive coverage with good depth' },
      { range: '8-10', label: 'Outstanding', description: 'Industry-leading, exemplary coverage' }
    ],
    examples: [
      { score: 2, description: 'Homepage with no product details or FAQ' },
      { score: 5, description: 'Basic product page with some features listed' },
      { score: 8, description: 'Comprehensive guides, FAQs, and detailed use cases' }
    ]
  },
  CES: {
    code: 'CES',
    title: 'Credibility, Evidence & Safety',
    description: 'Evaluates trust signals, evidence quality, and safety markers that AI models prioritize.',
    weight: 0.35,
    calculation_method: 'Average of 5 sub-scores (s1-s5), each rated 0-10. Final CES score = (s1 + s2 + s3 + s4 + s5) / 5',
    scoring_anchors: [
      { range: '0-2', label: 'Critical', description: 'No credibility signals, anonymous content' },
      { range: '2-4', label: 'Weak', description: 'Minimal trust markers, generic content' },
      { range: '4-6', label: 'Adequate', description: 'Basic credibility with some evidence' },
      { range: '6-8', label: 'Strong', description: 'Well-evidenced with clear authorship' },
      { range: '8-10', label: 'Outstanding', description: 'Authority-level trust with extensive proof' }
    ],
    examples: [
      { score: 2, description: 'Anonymous blog with no sources' },
      { score: 5, description: 'Company site with basic team info' },
      { score: 8, description: 'Expert content with citations, credentials, and case studies' }
    ]
  },
  MTS: {
    code: 'MTS',
    title: 'Machine-Readability & Technical Signals',
    description: 'Assesses technical optimization for AI crawlers, structured data, and semantic clarity.',
    weight: 0.25,
    calculation_method: 'Average of 5 sub-scores (s1-s5), each rated 0-10. Final MTS score = (s1 + s2 + s3 + s4 + s5) / 5',
    scoring_anchors: [
      { range: '0-2', label: 'Critical', description: 'Technically broken, inaccessible to AI' },
      { range: '2-4', label: 'Weak', description: 'Poor optimization, limited machine-readability' },
      { range: '4-6', label: 'Adequate', description: 'Basic technical SEO implemented' },
      { range: '6-8', label: 'Strong', description: 'Well-optimized with structured data' },
      { range: '8-10', label: 'Outstanding', description: 'Cutting-edge implementation, AI-first' }
    ],
    examples: [
      { score: 2, description: 'Flash site with no semantic HTML' },
      { score: 5, description: 'Standard WordPress site with basic SEO plugin' },
      { score: 8, description: 'Schema.org markup, JSON-LD, perfect HTML5 semantics' }
    ]
  }
};

// ============================================
// SUB-METRICS DEFINITIONS
// ============================================

export const AIC_SUB_METRICS: Record<string, SubMetricDefinition> = {
  s1: {
    code: 'AIC_s1',
    name: 'Intent Coverage',
    description: 'Does your content address the full spectrum of user intents and search queries?',
    calculation: 'Analyzed across 50+ common user queries related to your industry. Scored based on % of intents covered.',
    importance: 'Critical - If you don\'t cover user intents, AI won\'t recommend you'
  },
  s2: {
    code: 'AIC_s2',
    name: 'Directness',
    description: 'How quickly does your content get to the answer users are looking for?',
    calculation: 'Measures answer position and clarity in first 200 words. Direct answers = higher score.',
    importance: 'High - AI prefers content that answers immediately'
  },
  s3: {
    code: 'AIC_s3',
    name: 'Completeness & Depth',
    description: 'Does your content provide comprehensive coverage with supporting details?',
    calculation: 'Evaluates topic breadth, supporting details, expertise signals, and answer completeness.',
    importance: 'High - Depth differentiates you from competitors'
  },
  s4: {
    code: 'AIC_s4',
    name: 'Consistency & Recency',
    description: 'Is your information up-to-date and consistent across different pages?',
    calculation: 'Checks publication dates, update timestamps, cross-page consistency, and conflicting info.',
    importance: 'Medium - Outdated content hurts trust'
  },
  s5: {
    code: 'AIC_s5',
    name: 'Conversational Readiness',
    description: 'How well-suited is your content for AI-driven conversations and voice queries?',
    calculation: 'Analyzes natural language quality, Q&A format, dialogue patterns, and conversational tone.',
    importance: 'Growing - Voice and chat are the future'
  }
};

export const CES_SUB_METRICS: Record<string, SubMetricDefinition> = {
  s1: {
    code: 'CES_s1',
    name: 'Evidence Density',
    description: 'How well do you back up claims with data, sources, and verifiable facts?',
    calculation: 'Counts citations, statistics, studies, and verifiable facts per 1000 words. More evidence = higher score.',
    importance: 'Critical - AI heavily weights cited content'
  },
  s2: {
    code: 'CES_s2',
    name: 'Author & Organization Transparency',
    description: 'Can users and AI verify who created this content and their credentials?',
    calculation: 'Checks for author bios, credentials, organization details, contact info, and about pages.',
    importance: 'High - Transparency = trust'
  },
  s3: {
    code: 'CES_s3',
    name: 'Experience & Originality',
    description: 'Does content demonstrate first-hand expertise and original insights?',
    calculation: 'Detects original research, case studies, unique data, and first-hand experience vs generic content.',
    importance: 'High - Google E-E-A-T applies to AI too'
  },
  s4: {
    code: 'CES_s4',
    name: 'Safety & Disclaimers',
    description: 'Are appropriate warnings, limitations, and disclaimers disclosed?',
    calculation: 'Identifies medical disclaimers, financial warnings, limitation statements, and safety notices.',
    importance: 'Critical for regulated industries'
  },
  s5: {
    code: 'CES_s5',
    name: 'Freshness & Revision History',
    description: 'Is content current and regularly updated with visible revision dates?',
    calculation: 'Analyzes publication date, last modified date, update frequency patterns, and changelog presence.',
    importance: 'Medium - Fresh content ranks better'
  }
};

export const MTS_SUB_METRICS: Record<string, SubMetricDefinition> = {
  s1: {
    code: 'MTS_s1',
    name: 'Structure & Semantics',
    description: 'How well is your HTML structured for machine understanding?',
    calculation: 'Evaluates heading hierarchy (H1-H6), semantic HTML5 tags, ARIA labels, and logical document structure.',
    importance: 'Critical - Foundation of machine-readability'
  },
  s2: {
    code: 'MTS_s2',
    name: 'Schema & Metadata',
    description: 'Do you use structured data markup (Schema.org, JSON-LD, Open Graph)?',
    calculation: 'Checks for Schema.org markup types, JSON-LD implementation, Open Graph tags, and Twitter Cards.',
    importance: 'High - Direct signal to AI systems'
  },
  s3: {
    code: 'MTS_s3',
    name: 'Entity Clarity',
    description: 'Are key entities (people, places, products, brands) clearly defined and marked up?',
    calculation: 'Detects entity markup, Wikipedia links, disambiguating descriptions, and entity relationships.',
    importance: 'High - Helps AI understand "what" you are'
  },
  s4: {
    code: 'MTS_s4',
    name: 'Crawlability & Coverage',
    description: 'Can AI models easily discover and access all your important content?',
    calculation: 'Analyzes robots.txt, XML sitemaps, internal linking structure, page depth, and crawl budget.',
    importance: 'Critical - Invisible content = 0 score'
  },
  s5: {
    code: 'MTS_s5',
    name: 'Reusability',
    description: 'Is your content easy for AI to extract, parse, and reuse?',
    calculation: 'Checks for clean HTML, API availability, RSS feeds, clear licensing, and download options.',
    importance: 'Medium - Makes content "AI-friendly"'
  }
};

// ============================================
// COMPETITOR DISCOVERY METHODOLOGY
// ============================================

export const COMPETITOR_DISCOVERY_STEPS: CompetitorDiscoveryStep[] = [
  {
    step: 1,
    title: 'Industry Keyword Extraction',
    description: 'We analyze your website content to extract 50-100 core industry keywords using NLP',
    method: 'NLP analysis + TF-IDF + manual verification',
    icon: 'üîç',
    technical_details: 'Uses spaCy for entity extraction, OpenAI embeddings for semantic clustering, and TF-IDF for keyword importance scoring'
  },
  {
    step: 2,
    title: 'AI Response Mining',
    description: 'We query all 6 AI platforms with your keywords and track which brands appear in responses',
    method: 'Automated API queries across ChatGPT, Claude, Gemini, Perplexity, SearchGPT, Bing',
    icon: 'ü§ñ',
    technical_details: '300+ queries per analysis, capturing brand mentions, rankings, and citation frequency'
  },
  {
    step: 3,
    title: 'Semantic Similarity Analysis',
    description: 'Using embeddings, we find websites with similar content, products, and target audience',
    method: 'Vector similarity (cosine) using OpenAI embeddings',
    icon: 'üß†',
    technical_details: 'Generates embeddings for your content and compares against 10M+ indexed websites. Threshold: >0.75 cosine similarity'
  },
  {
    step: 4,
    title: 'Citation Pattern Analysis',
    description: 'We track which brands are frequently cited alongside yours across all platforms',
    method: 'Co-occurrence matrix analysis',
    icon: 'üìä',
    technical_details: 'Builds co-citation graphs, identifies brands mentioned in similar contexts, calculates association strength'
  },
  {
    step: 5,
    title: 'Manual Verification',
    description: 'Our system verifies competitors are genuine alternatives and filters false positives',
    method: 'Business model matching + category validation + human review',
    icon: '‚úì',
    technical_details: 'Checks for matching business models, validates category overlap, removes unrelated sites'
  }
];

// ============================================
// THE 7 CRITICAL CONSUMER QUESTIONS
// ============================================

export const CRITICAL_CONSUMER_QUESTIONS: ConsumerQuestion[] = [
  {
    category: 'Discovery',
    weight: 0.30,
    questions: [
      'What are the top [category] companies?',
      'Who are the leading [industry] providers in 2025?',
      'Best [product type] for [use case]?'
    ],
    metric: 'Brand Mention Frequency',
    why_it_matters: 'If your brand doesn\'t appear in discovery queries, you\'re invisible to potential customers'
  },
  {
    category: 'Discovery',
    weight: 0.30,
    questions: [
      'Who makes [product type]?',
      '[Industry] companies list'
    ],
    metric: 'Category Association',
    why_it_matters: 'Being associated with your category is the first step to consideration'
  },
  {
    category: 'Comparison',
    weight: 0.35,
    questions: [
      '[Your Brand] vs [Competitor] - which is better?',
      'Compare [Product A] and [Product B]',
      '[Competitor] alternatives?'
    ],
    metric: 'Head-to-Head Win Rate',
    why_it_matters: 'Most purchase decisions involve comparing 2-3 options. You must win these comparisons.'
  },
  {
    category: 'Comparison',
    weight: 0.35,
    questions: [
      'Pros and cons of [Your Brand]',
      '[Your Brand] vs [Competitor] features'
    ],
    metric: 'Feature Completeness Score',
    why_it_matters: 'Customers compare features. Incomplete information = lost sales.'
  },
  {
    category: 'Utility',
    weight: 0.35,
    questions: [
      'How to solve [problem] using [Your Product]?',
      '[Your Product] best practices',
      'How to get started with [Your Product]?'
    ],
    metric: 'Solution Depth & Actionability',
    why_it_matters: 'Customers need to know HOW to use your product. Utility content drives conversions.'
  },
  {
    category: 'Utility',
    weight: 0.35,
    questions: [
      '[Your Product] tutorial',
      '[Your Product] use cases'
    ],
    metric: 'Use Case Coverage',
    why_it_matters: 'Covering diverse use cases expands your addressable market'
  },
  {
    category: 'Utility',
    weight: 0.35,
    questions: [
      'Common mistakes with [Product Type]',
      '[Your Product] troubleshooting'
    ],
    metric: 'Problem-Solving Content',
    why_it_matters: 'Helping customers overcome obstacles builds loyalty and reduces churn'
  }
];

// ============================================
// COMPARISON FRAMEWORK (Discovery, Comparison, Utility)
// ============================================

export const COMPARISON_DIMENSIONS: Record<string, ComparisonDimension> = {
  discovery: {
    name: 'Discovery Score',
    weight: 0.30,
    description: 'How often does your brand appear in AI responses vs competitors when users are discovering options?',
    metrics: [
      'Mention frequency across platforms',
      'Citation rate in category queries',
      'Ranking position in lists',
      'Brand recall strength'
    ],
    calculation_formula: 'Discovery = (Mentions / Total_Category_Mentions) √ó 10'
  },
  comparison: {
    name: 'Comparison Score',
    weight: 0.35,
    description: 'When users compare options, how favorably are you positioned vs competitors?',
    metrics: [
      'Head-to-head win rate',
      'Feature completeness score',
      'Sentiment analysis (positive/negative)',
      'Recommendation frequency'
    ],
    calculation_formula: 'Comparison = (Wins / (Wins + Losses)) √ó 10'
  },
  utility: {
    name: 'Utility Score',
    weight: 0.35,
    description: 'How helpful and actionable is your content for solving user problems?',
    metrics: [
      'Solution depth (0-10)',
      'Implementation clarity',
      'Use case coverage',
      'Troubleshooting content quality'
    ],
    calculation_formula: 'Utility = Average(Solution_Depth, Implementation_Clarity, Use_Case_Coverage)'
  }
};

// ============================================
// TEST QUERIES FOR "OPEN IN CHATGPT" FEATURE
// ============================================

export function generateTestQueries(brandName: string, industry: string, competitors: string[]) {
  return {
    discovery: [
      `What are the top ${industry} companies in 2025?`,
      `Leading ${industry} providers?`,
      `Best ${industry} solutions for businesses?`,
      `Who makes ${industry} products?`
    ],
    comparison: [
      `${brandName} vs ${competitors[0]}`,
      `Compare ${brandName} and ${competitors[1]}`,
      `${brandName} alternatives`,
      `Pros and cons of ${brandName}`,
      `${competitors[0]} vs ${brandName} which is better?`
    ],
    utility: [
      `How to use ${brandName}?`,
      `${brandName} best practices`,
      `Getting started with ${brandName}`,
      `${brandName} tutorial`,
      `Common mistakes with ${brandName}`,
      `${brandName} troubleshooting guide`
    ],
    verification: [
      `What does ${brandName} do?`,
      `${brandName} features and pricing`,
      `${brandName} customer reviews`,
      `Who founded ${brandName}?`,
      `${brandName} headquarters location`
    ]
  };
}

// ============================================
// ACCURACY VERIFICATION FRAMEWORK
// ============================================

export interface AccuracyTestCase {
  category: 'basic_facts' | 'features' | 'pricing' | 'competitors' | 'use_cases';
  query: string;
  expected_facts: string[];
  is_critical: boolean;
  weight: number;
}

export function generateAccuracyTests(brandData: {
  name: string;
  foundedYear?: string;
  headquarters?: string;
  mainProduct?: string;
  pricingTiers?: string[];
  keyFeatures?: string[];
  competitors?: string[];
}): AccuracyTestCase[] {
  return [
    {
      category: 'basic_facts',
      query: `What does ${brandData.name} do?`,
      expected_facts: [
        brandData.mainProduct || 'core product/service',
        brandData.foundedYear ? `Founded in ${brandData.foundedYear}` : 'founding year',
        brandData.headquarters || 'headquarters location'
      ],
      is_critical: true,
      weight: 0.30
    },
    {
      category: 'competitors',
      query: `Who are ${brandData.name}'s main competitors?`,
      expected_facts: brandData.competitors || ['competitor names'],
      is_critical: true,
      weight: 0.25
    },
    {
      category: 'features',
      query: `What are ${brandData.name}'s key features?`,
      expected_facts: brandData.keyFeatures || ['main features'],
      is_critical: false,
      weight: 0.20
    },
    {
      category: 'pricing',
      query: `${brandData.name} pricing`,
      expected_facts: brandData.pricingTiers || ['pricing information'],
      is_critical: false,
      weight: 0.15
    },
    {
      category: 'use_cases',
      query: `What is ${brandData.name} best used for?`,
      expected_facts: ['primary use cases'],
      is_critical: false,
      weight: 0.10
    }
  ];
}

// ============================================
// SCORING SCALE CONSTANTS
// ============================================

export const SCORE_SCALE = {
  CRITICAL: { min: 0, max: 2, label: 'Critical', color: '#CC0000', description: 'Urgent issues requiring immediate attention' },
  WEAK: { min: 2, max: 4, label: 'Weak', color: '#FF6B6B', description: 'Significant gaps that hurt performance' },
  ADEQUATE: { min: 4, max: 6, label: 'Adequate', color: '#FFA500', description: 'Basic coverage, room for improvement' },
  STRONG: { min: 6, max: 8, label: 'Strong', color: '#4CAF50', description: 'Solid performance, competitive' },
  OUTSTANDING: { min: 8, max: 10, label: 'Outstanding', color: '#000000', description: 'Industry-leading, exemplary' }
};

export const DEFAULT_WEIGHTS = {
  AIC: 0.40,
  CES: 0.35,
  MTS: 0.25
};

export const AI_PLATFORMS = [
  { name: 'ChatGPT', code: 'chatgpt', url: 'https://chat.openai.com/', icon: 'ü§ñ', color: '#10A37F' },
  { name: 'Claude', code: 'claude', url: 'https://claude.ai/', icon: 'üß†', color: '#000000' },
  { name: 'Google Gemini', code: 'gemini', url: 'https://gemini.google.com/', icon: '‚ú®', color: '#4285F4' },
  { name: 'Perplexity', code: 'perplexity', url: 'https://www.perplexity.ai/', icon: 'üîç', color: '#20808D' },
  { name: 'SearchGPT', code: 'searchgpt', url: 'https://chatgpt.com/search', icon: 'üîé', color: '#10A37F' },
  { name: 'Bing Chat', code: 'bing', url: 'https://www.bing.com/chat', icon: 'üí¨', color: '#008373' }
];